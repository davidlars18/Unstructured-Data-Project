{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "10b6287bf8b33073c8a1f5154ee3838ebf67d3fb2cf2d10d6bedc5a780ce9d68"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from composable import pipeable\n",
    "import re as r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['',\n",
       " 'DOTC                                                                                 RUN DATE : 06/14/17 21:56',\n",
       " 'RPT DATE :06/14/17',\n",
       " 'TTS0126:SELL SHORT TRADES & SHORT EXEMPT',\n",
       " 'Symbol   Side    Cxl      Qty    Price       Bid        Ask        T-DatS-DatTradeID      TradeTiSS      Exbkr',\n",
       " '',\n",
       " 'TradeCommType  SourceCommission   Account   OrderID      GTL               Trailer Info               Clr',\n",
       " 'CERS     SS      NEW        2,756   2.400000    2.340000   2.45000006/1406/191706149900003 09:30:CustSS',\n",
       " '/17  /17  256945       00',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=GSCO',\n",
       " 'CERS     SS      NEW          100   2.36000018422.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX',\n",
       " '/17  /17  866087       04',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " 'CERS     SS      NEW          200   2.350000    2.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX',\n",
       " '/17  /17  866096       04',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " 'CERS     SS      NEW          100   2.350000    2.350000   2.36000006/1406/191706149900003 10:20:ContraSSFREX',\n",
       " '/17  /17  869780       23',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " 'CERS     SS      NEW          100   2.350000    2.350000   2.36000006/1406/191706149900003 10:22:ContraSSFREX',\n",
       " '/17  /17  892888       29',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " 'CERS     SS      NEW          100   2.360000    2.350000   2.36000006/1406/191706149900003 10:24:ContraSSFREX',\n",
       " '/17  /17  909119       01',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# reading in file\n",
    "with open('sell_short_trades_copy.txt') as f:\n",
    "    content = f.readlines()\n",
    "example = content[:29]\n",
    "example = [line.strip() for line in example]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['CERS     SS      NEW        2,756   2.400000    2.340000   2.45000006/1406/191706149900003 09:30:CustSS',\n",
       " 'CERS     SS      NEW          100   2.36000018422.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX',\n",
       " 'CERS     SS      NEW          200   2.350000    2.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX',\n",
       " 'CERS     SS      NEW          100   2.350000    2.350000   2.36000006/1406/191706149900003 10:20:ContraSSFREX',\n",
       " 'CERS     SS      NEW          100   2.350000    2.350000   2.36000006/1406/191706149900003 10:22:ContraSSFREX',\n",
       " 'CERS     SS      NEW          100   2.360000    2.350000   2.36000006/1406/191706149900003 10:24:ContraSSFREX']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "line_start = r.compile(r'(CERS    |S )')\n",
    "re_split_first_line_test = [line.strip() for line in example if line_start.match(line)]\n",
    "re_split_first_line_test[:20]\n",
    "# i thought maybe I test the beginning of each line with a regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "re_split_first_line = [line.strip() for line in content if line_start.match(line)]\n",
    "re_split_first_line[:20]\n",
    "# this worked, but now i have lost each row in between \n",
    "# I decided to give up on regex style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all my lambdas to check for what to get rid of\n",
    "# after all these functions, I will only have the rows of data. No headers or extra lines\n",
    "is_blank = lambda l: True if len(l.strip()) == 0 else False # blank lines or lines filled with only whitespace\n",
    "\n",
    "# removal with regular expressions (I know I have to remove multiple of these types of lines)\n",
    "dr = r.compile(r\"\\s*\\d+ of 77\\s*\") # regex for page number lines\n",
    "is_page_num_line = pipeable(lambda l: True if dr.match(l) else False) # check for page number lines\n",
    "headers = r.compile(r'^( Symbol | TradeCommType ).*') # regex for header lines\n",
    "no_headers = pipeable (lambda l: True if headers.match(l) else False) # check for header lines\n",
    "\n",
    "# basically copied and pasted these lambdas and changed what the startswith() paramater was, because these lines were specific and this was pretty quick\n",
    "# I only have to remove one of each of these types of lines\n",
    "totals = pipeable(lambda l: True if l.strip().startswith('TOTAL TRADES:') else False) # check for TOTAL TRADES line\n",
    "end = pipeable(lambda l: True if l.strip().startswith('*****') else False) # check for END OF REPORT line\n",
    "header1 = pipeable(lambda l: True if l.strip().startswith('DOTC') else False) # check for first header line\n",
    "header2 = pipeable(lambda l: True if l.strip().startswith('RPT DATE') else False) # check for second header line\n",
    "header3 = pipeable(lambda l: True if l.strip().startswith('TTS0126:SELL') else False) # check for third header line\n",
    "\n",
    "needs_removal = pipeable(lambda l: is_blank(l) or is_page_num_line(l) or no_headers(l) or totals(l) or end(l) or header1(l) or header2(l) or header3(l)) # full removal lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3499"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pure_data_lines = [l.strip() for l in content if not needs_removal(l)] \n",
    "len(pure_data_lines) # check to see if it is reasonable length\n",
    "# original data set length was "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yay\n"
     ]
    }
   ],
   "source": [
    "example1 = example[7]\n",
    "if line_start.match(example1):\n",
    "    print('yay')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = example[8]\n",
    "if line_start.match(example1):\n",
    "    print('yay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to regex stuff... Is there a way to add lines if they match/don't match? Lets find out\n",
    "testingdata1 = pure_data_lines[:20]\n",
    "line_start2 = r.compile(r'^((?!(CERS    |S    )).)*$')\n",
    "\n",
    "def regex_combine(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    lis = list(data)\n",
    "    current = 0\n",
    "    next = 1\n",
    "\n",
    "    while(current < len(lis) and (starts_condition(lis[current]) == False)): # get rid of all the lines in front of the ones that will begin with 'CERS ' or 'S '\n",
    "        # print('bye')\n",
    "        del(lis[current])\n",
    "\n",
    "    while(current < len(lis)): # updating the len(list) as we go so we do not go out of range with our index of current\n",
    "        current_item = lis[current] # get current item\n",
    "        next = current + 1 # next item will start as 1 after current\n",
    "        if (next >= len(lis)): # check that next is not out of range index\n",
    "            break\n",
    "        next_item = lis[next] # get next item\n",
    "        if line_start.match(current_item): # make sure current item fulfills start condition\n",
    "            while line_start2.match(next_item): # make sure next item fulfills its start condition\n",
    "                # print(next_item)\n",
    "                lis[current] = lis[current] + ' ' + next_item # add the two together\n",
    "\n",
    "                next += 1 # prepare to get the next item over\n",
    "                if (next >= len(lis)): # check that next item is not out of range index\n",
    "                    break\n",
    "                next_item = lis[next] # get next item\n",
    "\n",
    "            del lis[current+1:next] # delete the 'next' items that we added to current\n",
    "\n",
    "        current += 1 # increment\n",
    "\n",
    "    return lis\n",
    "\n",
    "    # I kept messing around with this trying to make it work\n",
    "    # but i can't do (while not line_start.match(next_item)): because it returns None, not True/False...\n",
    "    # BUT!!!! i did find a way to use r.compile(r'^((?!(CERS    |S )).)*$') to match rows that do not contain the CERS or S (thanks stack overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['',\n",
       " 'DOTC                                                                                 RUN DATE : 06/14/17 21:56',\n",
       " 'RPT DATE :06/14/17',\n",
       " 'TTS0126:SELL SHORT TRADES & SHORT EXEMPT',\n",
       " '',\n",
       " 'TradeCommType  SourceCommission   Account   OrderID      GTL               Trailer Info               Clr',\n",
       " '/17  /17  256945       00',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=GSCO',\n",
       " '/17  /17  866087       04',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " '/17  /17  866096       04',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " '/17  /17  869780       23',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300',\n",
       " '/17  /17  892888       29',\n",
       " '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS',\n",
       " '854300']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "line_start2 = r.compile(r'^((?!(CERS     |S    )).)*$')\n",
    "re_split_first_line_test2 = [line.strip() for line in example if line_start2.match(line)]\n",
    "re_split_first_line_test2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['CERS     SS      NEW        2,756   2.400000    2.340000   2.45000006/1406/191706149900003 09:30:CustSS /17  /17  256945       00 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=GSCO',\n",
       " 'CERS     SS      NEW          100   2.36000018422.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX /17  /17  866087       04 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          200   2.350000    2.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX /17  /17  866096       04 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          100   2.350000    2.350000   2.36000006/1406/191706149900003 10:20:ContraSSFREX /17  /17  869780       23 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          100   2.350000    2.350000   2.36000006/1406/191706149900003 10:22:ContraSSFREX /17  /17  892888       29 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          100   2.360000    2.350000   2.36000006/1406/191706149900003 10:24:ContraSSFREX']"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "regex_combine(testingdata1) # example test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "913"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "sorted = regex_combine(pure_data_lines) # tried it on full data set\n",
    "# BOOOM baby\n",
    "len(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will try it without regex because its fun\n",
    "starts_condition = pipeable(lambda line: True if line.startswith('CERS ') or line.startswith('S ') else False)\n",
    "\n",
    "def combine_rows(data):\n",
    "    \"\"\"\n",
    "    takes a list of strings whose data is split over multiple lines and combines the right rows into one line for each\n",
    "    Args: list of strings\n",
    "    returns: lists with each row of strings on one line\n",
    "    \"\"\"\n",
    "    data = list(data) # establish that our data must be in a list if it isn't already\n",
    "    counter = 0 # current item counter\n",
    "    next = 0 # next item counter\n",
    "\n",
    "    while (counter < len(data) and (starts_condition(data[counter]) == False)): # get rid of all the lines in front of the ones that will begin with 'CERS ' or 'S '\n",
    "        # print('bye')\n",
    "        del(data[counter])\n",
    "\n",
    "    stop_condition = len(data) # stop condition for loop is the length of list\n",
    "\n",
    "    while (counter < stop_condition): # while we are still within the length of the list. This will stop once our current item counter is at the end of the list\n",
    "        \n",
    "        current_item = data[counter] # get current item (first item will be data[0])\n",
    "        # print(current_item)\n",
    "        \n",
    "        if next >= len(data): # check for out of bounds (we are at the end of the list)\n",
    "            break\n",
    "        else:\n",
    "            next = counter + 1 # make the next counter 1 greater than the current counter value\n",
    "            next_item = data[next] # get the next item in the list\n",
    "\n",
    "        if (starts_condition(current_item) == True): # if the current item fulfills start condition, we want to begin the loop of adding the following lines\n",
    "            while not (starts_condition(next_item)): # while the next line does not start with 'CERS' or 'S' or 'STOP'\n",
    "                data[counter] = data[counter] + \" \" + next_item # adds the next line to the previous\n",
    "                # print(data[counter])\n",
    "                \n",
    "                next += 1 # increment next counter\n",
    "                if next >= len(data): # without this, when we get to the end of the list, it will index out of range because of the increment\n",
    "                    break\n",
    "                next_item = data[next] # get next item in list\n",
    "\n",
    "            del data[counter+1:next] # delete the items that we just added to current item\n",
    "            stop_condition = len(data) # update stop condition to the length of our updated list\n",
    "\n",
    "        counter += 1 # increment current item counter\n",
    "\n",
    "    return data\n",
    "\n",
    "    # I got this one to work too, but using the string.startswith() function, but I will test with my regex one instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regex_combine():\n",
    "    assert regex_combine(['CERS    34', 'asdf jkl', 'S    444', 'H', 'E', 'L', 'L', 'O', 'CERS    ']) == ['CERS    34 asdf jkl', 'S    444 H E L L O', 'CERS    ']\n",
    "    assert regex_combine(['sefe', 'sdfs']) == []\n",
    "    assert regex_combine(['SS', 'CERS    dsf', 'dsf', 'dsf', 'S    ', 'SS']) == ['CERS    dsf dsf dsf', 'S     SS']\n",
    "    assert regex_combine(['CERS     SS      NEW        2,756   2.400000    2.340000   2.45000006/1406/191706149900003 09:30:CustSS', '/17  /17  256945       00', '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=GSCO', 'CERS     SS      NEW          100   2.36000018422.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX', '/17  /17  866087       04', '0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS']) == ['CERS     SS      NEW        2,756   2.400000    2.340000   2.45000006/1406/191706149900003 09:30:CustSS /17  /17  256945       00 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=GSCO',\n",
    " 'CERS     SS      NEW          100   2.36000018422.360000   2.37000006/1406/191706149900003 10:20:ContraSSFREX /17  /17  866087       04 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS']\n",
    "\n",
    "test_regex_combine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['CERS     SS      NEW          200   2.350000    2.340000   2.35000006/1406/191706149900006 15:59:CustSS /17  /17  843318       57 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          100   2.350000    2.340000   2.35000006/1406/191706149900006 15:59:ContraSSDTTX /17  /17  843340       58 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          200   2.350000    2.340000   2.35000006/1406/191706149900006 15:59:CustSS /17  /17  843708       58 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300',\n",
       " 'CERS     SS      NEW          786   2.350000    2.340000   2.35000006/1406/191706149900006 15:59:CustSS /17  /17  844088       59 0704 PerUnit   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "testingdata2 = pure_data_lines[3483:]\n",
    "test1 = combine_rows(testingdata2)\n",
    "test1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "913"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "sorted1 = regex_combine(pure_data_lines)\n",
    "len(sorted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# need to find the headers and put them back in as the first row of the file\n",
    "headers = example[4] + '    ' + example[6]\n",
    "type(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'t   TERM  0.010000     AABBC     1706149900003#STA=CERS 854300'"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "almost_there = '\\n'.join(sorted1)\n",
    "# almost_there (inspecting the file)\n",
    "output = headers + '\\n' + almost_there\n",
    "# (inspecting output content before I write it)\n",
    "# output[1000]\n",
    "# len(output)\n",
    "# output[191000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it is time to write to a file\n",
    "with open('sell_short_trades_2.txt', 'w') as outfile:\n",
    "    outfile.write(output)"
   ]
  }
 ]
}